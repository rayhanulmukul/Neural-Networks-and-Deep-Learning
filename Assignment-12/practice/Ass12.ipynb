{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dde0112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 10:17:26.664374: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-28 10:17:27.386252: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-28 10:17:27.389362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-28 10:17:28.977448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import KLDivergence, SparseCategoricalCrossentropy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Define class names\n",
    "class_names = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e291c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced x_train shape: (20000, 32, 32, 3)\n",
      "Reduced y_train shape: (20000, 1)\n",
      "Class distribution: {0: 2000, 1: 2000, 2: 2000, 3: 2000, 4: 2000, 5: 2000, 6: 2000, 7: 2000, 8: 2000, 9: 2000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a new dataset with 2000 samples per class\n",
    "num_classes = 10\n",
    "samples_per_class = 2000\n",
    "\n",
    "# Arrays to collect selected samples\n",
    "x_train_reduced = []\n",
    "y_train_reduced = []\n",
    "\n",
    "# Track how many samples we've added per class\n",
    "class_counts = {i: 0 for i in range(num_classes)}\n",
    "\n",
    "# Iterate through the full training set\n",
    "for img, label in zip(x_train, y_train):\n",
    "    cls = label[0]\n",
    "    if class_counts[cls] < samples_per_class:\n",
    "        x_train_reduced.append(img)\n",
    "        y_train_reduced.append(label)\n",
    "        class_counts[cls] += 1\n",
    "    if sum(class_counts.values()) == samples_per_class * num_classes:\n",
    "        break\n",
    "\n",
    "# Convert to numpy arrays\n",
    "x_train_reduced = np.array(x_train_reduced)\n",
    "y_train_reduced = np.array(y_train_reduced)\n",
    "\n",
    "# Final shape confirmation\n",
    "print(\"Reduced x_train shape:\", x_train_reduced.shape)\n",
    "print(\"Reduced y_train shape:\", y_train_reduced.shape)\n",
    "\n",
    "# Optional: check class distribution\n",
    "(unique, counts) = np.unique(y_train_reduced, return_counts=True)\n",
    "print(\"Class distribution:\", dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95240d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_reduced\n",
    "y_train = y_train_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4c679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small CNN Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 356810 (1.36 MB)\n",
      "Trainable params: 356810 (1.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 10:17:33.880129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: tesla\n",
      "2025-07-28 10:17:33.880164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: tesla\n",
      "2025-07-28 10:17:33.880315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2025-07-28 10:17:33.880369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 575.64.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - 11s 33ms/step - loss: 1.7801 - accuracy: 0.3415 - val_loss: 1.5414 - val_accuracy: 0.4471\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 1.4060 - accuracy: 0.4925 - val_loss: 1.3629 - val_accuracy: 0.5105\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 1.2472 - accuracy: 0.5561 - val_loss: 1.1949 - val_accuracy: 0.5781\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 1.1192 - accuracy: 0.6050 - val_loss: 1.1321 - val_accuracy: 0.6011\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 1.0317 - accuracy: 0.6380 - val_loss: 1.0994 - val_accuracy: 0.6113\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.9475 - accuracy: 0.6703 - val_loss: 1.0998 - val_accuracy: 0.6092\n",
      "Epoch 7/15\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.8720 - accuracy: 0.6940 - val_loss: 1.0027 - val_accuracy: 0.6525\n",
      "Epoch 8/15\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.8031 - accuracy: 0.7168 - val_loss: 1.0985 - val_accuracy: 0.6219\n",
      "Epoch 9/15\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.7496 - accuracy: 0.7362 - val_loss: 1.0123 - val_accuracy: 0.6451\n",
      "Epoch 10/15\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.6758 - accuracy: 0.7650 - val_loss: 0.9960 - val_accuracy: 0.6666\n",
      "Epoch 11/15\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.6150 - accuracy: 0.7868 - val_loss: 1.0650 - val_accuracy: 0.6490\n",
      "Epoch 12/15\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.5532 - accuracy: 0.8073 - val_loss: 1.0096 - val_accuracy: 0.6701\n",
      "Epoch 13/15\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.4843 - accuracy: 0.8301 - val_loss: 1.0996 - val_accuracy: 0.6544\n",
      "Epoch 14/15\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.4445 - accuracy: 0.8465 - val_loss: 1.0773 - val_accuracy: 0.6701\n",
      "Epoch 15/15\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.3966 - accuracy: 0.8630 - val_loss: 1.1947 - val_accuracy: 0.6495\n"
     ]
    }
   ],
   "source": [
    "def build_small_cnn(input_shape, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "small_cnn = build_small_cnn(x_train.shape[1:], len(class_names))\n",
    "small_cnn.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(\"Small CNN Summary:\")\n",
    "small_cnn.summary()\n",
    "\n",
    "# Train the small CNN\n",
    "history_small_cnn = small_cnn.fit(x_train, y_train, epochs=15,\n",
    "                                  validation_data=(x_test, y_test),\n",
    "                                  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8290d4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1947 - accuracy: 0.6495\n",
      "Small CNN Test Accuracy: 64.95%\n"
     ]
    }
   ],
   "source": [
    "small_cnn_loss, small_cnn_accuracy = small_cnn.evaluate(x_test, y_test)\n",
    "print(f\"Small CNN Test Accuracy: {small_cnn_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0df766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned VGG16 Summary:\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14982474 (57.15 MB)\n",
      "Trainable params: 267786 (1.02 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 138s 440ms/step - loss: 2.0680 - accuracy: 0.2580 - val_loss: 1.7114 - val_accuracy: 0.4371\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 140s 448ms/step - loss: 1.6897 - accuracy: 0.4092 - val_loss: 1.5295 - val_accuracy: 0.4879\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 140s 448ms/step - loss: 1.5465 - accuracy: 0.4665 - val_loss: 1.4446 - val_accuracy: 0.5121\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 139s 444ms/step - loss: 1.4638 - accuracy: 0.4963 - val_loss: 1.3900 - val_accuracy: 0.5319\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 139s 443ms/step - loss: 1.4110 - accuracy: 0.5141 - val_loss: 1.3521 - val_accuracy: 0.5426\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 135s 431ms/step - loss: 1.3663 - accuracy: 0.5286 - val_loss: 1.3264 - val_accuracy: 0.5479\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 133s 425ms/step - loss: 1.3430 - accuracy: 0.5407 - val_loss: 1.3019 - val_accuracy: 0.5550\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 133s 427ms/step - loss: 1.3049 - accuracy: 0.5534 - val_loss: 1.2821 - val_accuracy: 0.5601\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 133s 426ms/step - loss: 1.2880 - accuracy: 0.5578 - val_loss: 1.2696 - val_accuracy: 0.5640\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 132s 421ms/step - loss: 1.2650 - accuracy: 0.5683 - val_loss: 1.2523 - val_accuracy: 0.5691\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data for VGG16 (upsample images)\n",
    "x_train_vgg = tf.image.resize(x_train, (48, 48))\n",
    "x_test_vgg = tf.image.resize(x_test, (48, 48))\n",
    "\n",
    "# Load VGG16 with pre-trained ImageNet weights, excluding the top classification layer\n",
    "base_model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze the convolutional base\n",
    "base_model_vgg.trainable = False\n",
    "\n",
    "# Add a new classifier head\n",
    "x = layers.Flatten()(base_model_vgg.output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "vgg16_finetuned = Model(inputs=base_model_vgg.input, outputs=outputs)\n",
    "\n",
    "vgg16_finetuned.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "print(\"Fine-tuned VGG16 Summary:\")\n",
    "vgg16_finetuned.summary()\n",
    "\n",
    "# Train the fine-tuned VGG16\n",
    "history_vgg16 = vgg16_finetuned.fit(x_train_vgg, y_train, epochs=10,\n",
    "                                    validation_data=(x_test_vgg, y_test),\n",
    "                                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 44s 141ms/step - loss: 1.2523 - accuracy: 0.5691\n",
      "Fine-tuned VGG16 Test Accuracy: 56.91%\n"
     ]
    }
   ],
   "source": [
    "vgg16_loss, vgg16_accuracy = vgg16_finetuned.evaluate(x_test_vgg, y_test)\n",
    "print(f\"Fine-tuned VGG16 Test Accuracy: {vgg16_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f19e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 10:43:17.845505: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 12042240000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data for ResNet50\n",
    "x_train_resnet = tf.image.resize(x_train, (224, 224)) # ResNet50 was trained on 224x224\n",
    "x_test_resnet = tf.image.resize(x_test, (224, 224))\n",
    "\n",
    "# Load ResNet50 with pre-trained ImageNet weights\n",
    "base_model_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model_resnet.trainable = False\n",
    "\n",
    "# Add a new classifier head\n",
    "x = layers.GlobalAveragePooling2D()(base_model_resnet.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "resnet50_finetuned = Model(inputs=base_model_resnet.input, outputs=outputs)\n",
    "\n",
    "resnet50_finetuned.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                           loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "print(\"Fine-tuned ResNet50 Summary:\")\n",
    "resnet50_finetuned.summary()\n",
    "\n",
    "# Train the fine-tuned ResNet50\n",
    "history_resnet50 = resnet50_finetuned.fit(x_train_resnet, y_train, epochs=10,\n",
    "                                          validation_data=(x_test_resnet, y_test),\n",
    "                                          batch_size=32) # Smaller batch size for larger images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_loss, resnet50_accuracy = resnet50_finetuned.evaluate(x_test_resnet, y_test)\n",
    "print(f\"Fine-tuned ResNet50 Test Accuracy: {resnet50_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        # The teacher model needs upscaled images\n",
    "        teacher_predictions = self.teacher(tf.image.resize(x, (224, 224)), training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Create a new instance of the small CNN as the student\n",
    "student_model = build_small_cnn(x_train.shape[1:], len(class_names))\n",
    "\n",
    "# Initialize and compile the distiller\n",
    "distiller = Distiller(student=student_model, teacher=resnet50_finetuned)\n",
    "distiller.compile(\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'],\n",
    "    student_loss_fn=SparseCategoricalCrossentropy(from_logits=False),\n",
    "    distillation_loss_fn=KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill knowledge from teacher to student\n",
    "history_distiller = distiller.fit(x_train, y_train, epochs=15,\n",
    "                                  validation_data=(x_test, y_test),\n",
    "                                  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbe11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_loss, student_accuracy = distiller.student.evaluate(x_test, y_test)\n",
    "print(f\"Distilled Student Model Test Accuracy: {student_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ba969",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_loss, student_accuracy = distiller.student.evaluate(x_test, y_test)\n",
    "print(f\"Distilled Student Model Test Accuracy: {student_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"1. Small CNN (Baseline) Accuracy: {small_cnn_accuracy * 100:.2f}%\")\n",
    "print(f\"2. Fine-tuned VGG16 Accuracy: {vgg16_accuracy * 100:.2f}%\")\n",
    "print(f\"3. Fine-tuned ResNet50 Accuracy: {resnet50_accuracy * 100:.2f}%\")\n",
    "print(f\"4. Distilled Small CNN (Student) Accuracy: {student_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plotting the results\n",
    "models = ['Small CNN', 'Fine-tuned VGG16', 'Fine-tuned ResNet50', 'Distilled CNN']\n",
    "accuracies = [small_cnn_accuracy, vgg16_accuracy, resnet50_accuracy, student_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, accuracies, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Classifier Performances')\n",
    "plt.ylim([0, 1])\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc + 0.01, f\"{acc*100:.2f}%\", ha='center')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
