{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a5a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 17:12:55.227824: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-22 17:12:55.227869: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-22 17:12:55.229227: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-22 17:12:55.239993: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-22 17:12:58.842999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Verification Models Comparison Workflow\n",
      "==================================================\n",
      "Creating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 17:13:06.123743: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-22 17:13:06.268671: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BCE Model Architecture ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bce_face_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bce_face_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">129,000</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │        \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │     \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │          \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ embeddings (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │     \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)              │    \u001b[38;5;34m129,000\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">550,824</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m550,824\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">550,568</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m550,568\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 550,824\n",
      "Trainable weights: 14\n",
      "Non-trainable weights: 2\n",
      "\n",
      "=== Contrastive Model Architecture ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"contrastive_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"contrastive_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\"> Param # </span>┃<span style=\"font-weight: bold\"> Connected to         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ face_embedding_mod… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">421,312</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │         │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ distance (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                     │                   │         │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mParam #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │       \u001b[38;5;34m0\u001b[0m │ -                    │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │       \u001b[38;5;34m0\u001b[0m │ -                    │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ face_embedding_mod… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │ \u001b[38;5;34m421,312\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │         │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m0\u001b[0m │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m0\u001b[0m │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ distance (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │       \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                     │                   │         │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,312</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,312\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,312</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,312\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 421,312\n",
      "Trainable weights: 10\n",
      "Non-trainable weights: 0\n",
      "\n",
      "=== Triplet Model Architecture ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"triplet_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"triplet_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\"> Param # </span>┃<span style=\"font-weight: bold\"> Connected to         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ anchor (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ positive            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ negative            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ face_embedding_mod… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">421,312</span> │ anchor[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │         │ positive[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │         │ negative[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │         │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │         │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mParam #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ anchor (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │       \u001b[38;5;34m0\u001b[0m │ -                    │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ positive            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │       \u001b[38;5;34m0\u001b[0m │ -                    │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ negative            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │       \u001b[38;5;34m0\u001b[0m │ -                    │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │         │                      │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ face_embedding_mod… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │ \u001b[38;5;34m421,312\u001b[0m │ anchor[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │         │ positive[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │         │ negative[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m0\u001b[0m │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m0\u001b[0m │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m0\u001b[0m │ face_embedding_mode… │\n",
       "├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │       \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │         │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │         │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,312</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,312\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,312</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,312\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 421,312\n",
      "Trainable weights: 10\n",
      "Non-trainable weights: 0\n",
      "\n",
      "=== Sanity Check: BCE Model ===\n",
      "✓ Forward pass successful, output shape: (1, 1000)\n",
      "✓ Gradient computation successful, 14/14 variables have gradients\n",
      "\n",
      "=== Sanity Check: Contrastive Model ===\n",
      "✓ Forward pass successful, output shape: (1, 1)\n",
      "✓ Gradient computation successful, 10/10 variables have gradients\n",
      "\n",
      "=== Sanity Check: Triplet Model ===\n",
      "✓ Forward pass successful, output shape: (1, 384)\n",
      "✓ Gradient computation successful, 10/10 variables have gradients\n",
      "\n",
      "✓ All models created and validated successfully!\n",
      "Next steps:\n",
      "1. Load your face dataset (LFW, VGGFace2, etc.)\n",
      "2. Preprocess and create appropriate data loaders\n",
      "3. Train each model with the provided compile functions\n",
      "4. Use the evaluation functions to compare performance\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. DATA PREPARATION & LOADING\n",
    "# =============================================================================\n",
    "\n",
    "def create_face_embedding_model(input_shape=(224, 224, 3), embedding_dim=128):\n",
    "    \"\"\"Create base CNN for face feature extraction\"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Using a simple CNN - replace with ResNet50, VGGFace, etc. for better results\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    embeddings = layers.Dense(embedding_dim, activation=None, name='embeddings')(x)\n",
    "    \n",
    "    return Model(inputs, embeddings, name='face_embedding_model')\n",
    "\n",
    "# =============================================================================\n",
    "# 2. MODEL 1: BINARY CROSS-ENTROPY (CLASSIFICATION APPROACH)\n",
    "# =============================================================================\n",
    "\n",
    "def create_bce_model(num_classes, input_shape=(224, 224, 3), embedding_dim=128):\n",
    "    \"\"\"Face verification using classification with BCE loss\"\"\"\n",
    "    base_model = create_face_embedding_model(input_shape, embedding_dim)\n",
    "    \n",
    "    # Add classification head\n",
    "    embeddings = base_model.output\n",
    "    embeddings = layers.BatchNormalization()(embeddings)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax', name='predictions')(embeddings)\n",
    "    \n",
    "    model = Model(base_model.input, predictions, name='bce_face_model')\n",
    "    return model, base_model\n",
    "\n",
    "def compile_bce_model(model, learning_rate=1e-3):\n",
    "    \"\"\"Compile BCE model\"\"\"\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MODEL 2: CONTRASTIVE LOSS (SIAMESE NETWORK)\n",
    "# =============================================================================\n",
    "\n",
    "def contrastive_loss(margin=1.0):\n",
    "    \"\"\"Contrastive loss function for siamese networks\"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        # y_true: 1 if same person, 0 if different person\n",
    "        # y_pred: distance between embeddings\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    return loss\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    \"\"\"Compute euclidean distance between two vectors\"\"\"\n",
    "    x, y = vectors\n",
    "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "def create_contrastive_model(input_shape=(224, 224, 3), embedding_dim=128):\n",
    "    \"\"\"Create siamese network for contrastive learning\"\"\"\n",
    "    base_model = create_face_embedding_model(input_shape, embedding_dim)\n",
    "    \n",
    "    # Create siamese architecture\n",
    "    input_a = keras.Input(shape=input_shape)\n",
    "    input_b = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Get embeddings for both inputs\n",
    "    embedding_a = base_model(input_a)\n",
    "    embedding_b = base_model(input_b)\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    embedding_a = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(embedding_a)\n",
    "    embedding_b = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(embedding_b)\n",
    "    \n",
    "    # Compute distance\n",
    "    distance = layers.Lambda(euclidean_distance, name='distance')([embedding_a, embedding_b])\n",
    "    \n",
    "    model = Model([input_a, input_b], distance, name='contrastive_model')\n",
    "    return model, base_model\n",
    "\n",
    "def compile_contrastive_model(model, learning_rate=1e-3, margin=1.0):\n",
    "    \"\"\"Compile contrastive model\"\"\"\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=contrastive_loss(margin=margin),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# 4. MODEL 3: TRIPLET LOSS\n",
    "# =============================================================================\n",
    "\n",
    "def triplet_loss(alpha=0.2):\n",
    "    \"\"\"Triplet loss function\"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        # y_pred contains [anchor, positive, negative] embeddings\n",
    "        anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
    "        \n",
    "        # Calculate distances\n",
    "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "        \n",
    "        # Triplet loss\n",
    "        basic_loss = pos_dist - neg_dist + alpha\n",
    "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0))\n",
    "        return loss\n",
    "    return loss\n",
    "\n",
    "def create_triplet_model(input_shape=(224, 224, 3), embedding_dim=128):\n",
    "    \"\"\"Create triplet network\"\"\"\n",
    "    base_model = create_face_embedding_model(input_shape, embedding_dim)\n",
    "    \n",
    "    # Three inputs: anchor, positive, negative\n",
    "    anchor_input = keras.Input(shape=input_shape, name='anchor')\n",
    "    positive_input = keras.Input(shape=input_shape, name='positive')\n",
    "    negative_input = keras.Input(shape=input_shape, name='negative')\n",
    "    \n",
    "    # Get embeddings\n",
    "    anchor_embedding = base_model(anchor_input)\n",
    "    positive_embedding = base_model(positive_input)\n",
    "    negative_embedding = base_model(negative_input)\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    anchor_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(anchor_embedding)\n",
    "    positive_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(positive_embedding)\n",
    "    negative_embedding = layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(negative_embedding)\n",
    "    \n",
    "    # Combine embeddings for loss calculation\n",
    "    merged_output = layers.concatenate([anchor_embedding, positive_embedding, negative_embedding], axis=1)\n",
    "    \n",
    "    model = Model([anchor_input, positive_input, negative_input], merged_output, name='triplet_model')\n",
    "    return model, base_model\n",
    "\n",
    "def compile_triplet_model(model, learning_rate=1e-3, alpha=0.2):\n",
    "    \"\"\"Compile triplet model\"\"\"\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=triplet_loss(alpha=alpha)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# 5. TRAINING UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "class DebugCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Custom callback to monitor training progress\"\"\"\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs.get('loss', 0))\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"{self.model_name} - Epoch {epoch}: Loss = {logs.get('loss', 0):.4f}\")\n",
    "\n",
    "def create_callbacks(model_name, patience=10):\n",
    "    \"\"\"Create training callbacks\"\"\"\n",
    "    return [\n",
    "        keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
    "        DebugCallback(model_name)\n",
    "    ]\n",
    "\n",
    "# =============================================================================\n",
    "# 6. EVALUATION & VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def compute_embeddings(model, data):\n",
    "    \"\"\"Extract embeddings from trained model\"\"\"\n",
    "    if hasattr(model, 'layers') and len(model.layers) > 1:\n",
    "        # For BCE model, extract from embedding layer\n",
    "        embedding_model = Model(model.input, model.get_layer('embeddings').output)\n",
    "        return embedding_model.predict(data)\n",
    "    else:\n",
    "        # For contrastive/triplet models, use base model\n",
    "        return model.predict(data)\n",
    "\n",
    "def plot_training_history(histories, model_names):\n",
    "    \"\"\"Plot training histories for comparison\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
    "        plt.plot(history.history['loss'], label=f'{name} Train')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label=f'{name} Val', linestyle='--')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot accuracy (for BCE model)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
    "        if 'accuracy' in history.history:\n",
    "            plt.plot(history.history['accuracy'], label=f'{name} Train')\n",
    "            if 'val_accuracy' in history.history:\n",
    "                plt.plot(history.history['val_accuracy'], label=f'{name} Val', linestyle='--')\n",
    "    plt.title('Training Accuracy (BCE Model)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot learning rate\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
    "        if 'lr' in history.history:\n",
    "            plt.plot(history.history['lr'], label=name)\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_embeddings_tsne(embeddings, labels, title=\"Embedding Visualization\"):\n",
    "    \"\"\"Visualize embeddings using t-SNE\"\"\"\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap='tab10', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.colorbar(scatter)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def compute_verification_metrics(embeddings1, embeddings2, labels):\n",
    "    \"\"\"Compute face verification metrics\"\"\"\n",
    "    # Calculate distances\n",
    "    distances = np.linalg.norm(embeddings1 - embeddings2, axis=1)\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(labels, -distances)  # Negative distances for similarity\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Find Equal Error Rate (EER)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.absolute(fnr - fpr))\n",
    "    eer = fpr[eer_idx]\n",
    "    \n",
    "    return fpr, tpr, roc_auc, eer, thresholds[eer_idx]\n",
    "\n",
    "def plot_roc_comparison(results_dict):\n",
    "    \"\"\"Plot ROC curves for all models\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for model_name, (fpr, tpr, auc_score, eer) in results_dict.items():\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f}, EER = {eer:.3f})', linewidth=2)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves Comparison: Face Verification Models')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def plot_distance_distributions(genuine_distances, impostor_distances, model_name):\n",
    "    \"\"\"Plot distance distributions for genuine and impostor pairs\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.hist(genuine_distances, bins=50, alpha=0.7, label='Genuine Pairs', color='green', density=True)\n",
    "    plt.hist(impostor_distances, bins=50, alpha=0.7, label='Impostor Pairs', color='red', density=True)\n",
    "    \n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Distance Distribution - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 7. DEBUGGING UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def debug_model_architecture(model, model_name):\n",
    "    \"\"\"Print model architecture for debugging\"\"\"\n",
    "    print(f\"\\n=== {model_name} Architecture ===\")\n",
    "    model.summary()\n",
    "    print(f\"Total parameters: {model.count_params():,}\")\n",
    "    \n",
    "    # Check if gradients flow\n",
    "    print(f\"Trainable weights: {len(model.trainable_weights)}\")\n",
    "    print(f\"Non-trainable weights: {len(model.non_trainable_weights)}\")\n",
    "\n",
    "def debug_data_shapes(data_dict):\n",
    "    \"\"\"Debug data shapes and types\"\"\"\n",
    "    print(\"\\n=== Data Shape Debug ===\")\n",
    "    for name, data in data_dict.items():\n",
    "        if isinstance(data, (list, tuple)):\n",
    "            print(f\"{name}: {len(data)} items, shapes: {[d.shape for d in data]}\")\n",
    "        else:\n",
    "            print(f\"{name}: {data.shape}, dtype: {data.dtype}\")\n",
    "\n",
    "def sanity_check_model(model, sample_data, model_name):\n",
    "    \"\"\"Perform sanity checks on model\"\"\"\n",
    "    print(f\"\\n=== Sanity Check: {model_name} ===\")\n",
    "    \n",
    "    # Forward pass test\n",
    "    try:\n",
    "        if isinstance(sample_data, (list, tuple)):\n",
    "            output = model(sample_data)\n",
    "        else:\n",
    "            output = model([sample_data])\n",
    "        print(f\"✓ Forward pass successful, output shape: {output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Forward pass failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Gradient test\n",
    "    try:\n",
    "        with tf.GradientTape() as tape:\n",
    "            if isinstance(sample_data, (list, tuple)):\n",
    "                prediction = model(sample_data, training=True)\n",
    "            else:\n",
    "                prediction = model([sample_data], training=True)\n",
    "            loss = tf.reduce_mean(prediction)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        non_none_grads = [g for g in gradients if g is not None]\n",
    "        print(f\"✓ Gradient computation successful, {len(non_none_grads)}/{len(gradients)} variables have gradients\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Gradient computation failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# =============================================================================\n",
    "# 8. EXAMPLE USAGE & MAIN WORKFLOW\n",
    "# =============================================================================\n",
    "\n",
    "def main_comparison_workflow():\n",
    "    \"\"\"Example workflow for comparing the three models\"\"\"\n",
    "    print(\"Face Verification Models Comparison Workflow\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Model parameters\n",
    "    input_shape = (224, 224, 3)\n",
    "    embedding_dim = 128\n",
    "    num_classes = 1000  # Adjust based on your dataset\n",
    "    \n",
    "    # Create models\n",
    "    print(\"Creating models...\")\n",
    "    bce_model, bce_base = create_bce_model(num_classes, input_shape, embedding_dim)\n",
    "    contrastive_model, contrastive_base = create_contrastive_model(input_shape, embedding_dim)\n",
    "    triplet_model, triplet_base = create_triplet_model(input_shape, embedding_dim)\n",
    "    \n",
    "    # Compile models\n",
    "    compile_bce_model(bce_model)\n",
    "    compile_contrastive_model(contrastive_model)\n",
    "    compile_triplet_model(triplet_model)\n",
    "    \n",
    "    # Debug architectures\n",
    "    debug_model_architecture(bce_model, \"BCE Model\")\n",
    "    debug_model_architecture(contrastive_model, \"Contrastive Model\")\n",
    "    debug_model_architecture(triplet_model, \"Triplet Model\")\n",
    "    \n",
    "    # Create sample data for sanity checks\n",
    "    sample_image = np.random.random((1,) + input_shape).astype(np.float32)\n",
    "    sample_pair = [sample_image, sample_image]\n",
    "    sample_triplet = [sample_image, sample_image, sample_image]\n",
    "    \n",
    "    # Sanity checks\n",
    "    sanity_check_model(bce_model, sample_image, \"BCE Model\")\n",
    "    sanity_check_model(contrastive_model, sample_pair, \"Contrastive Model\")\n",
    "    sanity_check_model(triplet_model, sample_triplet, \"Triplet Model\")\n",
    "    \n",
    "    print(\"\\n✓ All models created and validated successfully!\")\n",
    "    print(\"Next steps:\")\n",
    "    print(\"1. Load your face dataset (LFW, VGGFace2, etc.)\")\n",
    "    print(\"2. Preprocess and create appropriate data loaders\")\n",
    "    print(\"3. Train each model with the provided compile functions\")\n",
    "    print(\"4. Use the evaluation functions to compare performance\")\n",
    "    \n",
    "    return {\n",
    "        'bce_model': bce_model,\n",
    "        'contrastive_model': contrastive_model,\n",
    "        'triplet_model': triplet_model,\n",
    "        'bce_base': bce_base,\n",
    "        'contrastive_base': contrastive_base,\n",
    "        'triplet_base': triplet_base\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    models = main_comparison_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2631e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Complete Face Verification Models Comparison\n",
    "Trains and compares BCE, Contrastive, and Triplet Loss models\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce TF warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Import our custom modules (assumes previous scripts are saved as modules)\n",
    "# from face_verifier_models import *  # Your model definitions\n",
    "# from face_data_pipeline import *     # Your data pipeline\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class FaceVerificationComparison:\n",
    "    \"\"\"Main class to orchestrate the complete comparison\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path, dataset_type='lfw', image_size=(224, 224)):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.dataset_type = dataset_type\n",
    "        self.image_size = image_size\n",
    "        self.results = {}\n",
    "        self.models = {}\n",
    "        self.histories = {}\n",
    "        \n",
    "    def setup_experiment(self):\n",
    "        \"\"\"Setup the complete experiment\"\"\"\n",
    "        print(\"🚀 Setting up Face Verification Comparison Experiment\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 1. Load and prepare data\n",
    "        print(\"📊 Loading and preparing dataset...\")\n",
    "        self.data_pipeline = complete_training_workflow(\n",
    "            self.dataset_path, self.dataset_type\n",
    "        )\n",
    "        \n",
    "        # 2. Create models\n",
    "        print(\"\\n🏗️  Creating models...\")\n",
    "        self.create_models()\n",
    "        \n",
    "        # 3. Show experiment info\n",
    "        self.show_experiment_info()\n",
    "        \n",
    "    def create_models(self):\n",
    "        \"\"\"Create all three models\"\"\"\n",
    "        num_classes = self.data_pipeline['num_classes']\n",
    "        \n",
    "        # BCE Model\n",
    "        bce_model, bce_base = create_bce_model(\n",
    "            num_classes, self.image_size + (3,), embedding_dim=128\n",
    "        )\n",
    "        compile_bce_model(bce_model, learning_rate=1e-3)\n",
    "        \n",
    "        # Contrastive Model\n",
    "        contrastive_model, contrastive_base = create_contrastive_model(\n",
    "            self.image_size + (3,), embedding_dim=128\n",
    "        )\n",
    "        compile_contrastive_model(contrastive_model, learning_rate=1e-3, margin=1.0)\n",
    "        \n",
    "        # Triplet Model\n",
    "        triplet_model, triplet_base = create_triplet_model(\n",
    "            self.image_size + (3,), embedding_dim=128\n",
    "        )\n",
    "        compile_triplet_model(triplet_model, learning_rate=1e-3, alpha=0.2)\n",
    "        \n",
    "        self.models = {\n",
    "            'BCE': {'full': bce_model, 'base': bce_base},\n",
    "            'Contrastive': {'full': contrastive_model, 'base': contrastive_base},\n",
    "            'Triplet': {'full': triplet_model, 'base': triplet_base}\n",
    "        }\n",
    "        \n",
    "        print(\"✅ All models created successfully!\")\n",
    "        \n",
    "    def show_experiment_info(self):\n",
    "        \"\"\"Display experiment information\"\"\"\n",
    "        info = self.data_pipeline['dataset_info']\n",
    "        \n",
    "        print(f\"\\n📋 Experiment Configuration:\")\n",
    "        print(f\"   Dataset: {self.dataset_type.upper()}\")\n",
    "        print(f\"   Total Images: {info['total_images']:,}\")\n",
    "        print(f\"   Identities: {info['num_identities']:,}\")\n",
    "        print(f\"   Classes (BCE): {self.data_pipeline['num_classes']:,}\")\n",
    "        print(f\"   Image Size: {self.image_size}\")\n",
    "        print(f\"   Train/Val/Test Split: {info['splits']['train']}/{info['splits']['val']}/{info['splits']['test']}\")\n",
    "        \n",
    "        print(f\"\\n🎯 Test Setup:\")\n",
    "        test_info = self.data_pipeline['test_data']\n",
    "        print(f\"   Verification Pairs: {len(test_info['pairs']):,}\")\n",
    "        print(f\"   Positive Pairs: {sum(test_info['labels']):,}\")\n",
    "        print(f\"   Negative Pairs: {len(test_info['labels']) - sum(test_info['labels']):,}\")\n",
    "        \n",
    "    def train_all_models(self, epochs=30, quick_test=False):\n",
    "        \"\"\"Train all three models\"\"\"\n",
    "        if quick_test:\n",
    "            epochs = 3\n",
    "            print(\"🏃 Quick test mode: Training for only 3 epochs\")\n",
    "        \n",
    "        print(f\"\\n🎯 Training all models for {epochs} epochs...\")\n",
    "        \n",
    "        generators = self.data_pipeline['generators']\n",
    "        \n",
    "        # Train BCE Model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📈 Training BCE (Classification) Model\")\n",
    "        print(\"=\"*50)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.histories['BCE'] = train_bce_model(\n",
    "            self.models['BCE']['full'],\n",
    "            generators['bce_train'],\n",
    "            generators['bce_val'],\n",
    "            epochs=epochs\n",
    "        )\n",
    "        \n",
    "        bce_time = time.time() - start_time\n",
    "        print(f\"⏱️  BCE Training completed in {bce_time:.1f}s\")\n",
    "        \n",
    "        # Train Contrastive Model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📈 Training Contrastive (Siamese) Model\")\n",
    "        print(\"=\"*50)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.histories['Contrastive'] = train_contrastive_model(\n",
    "            self.models['Contrastive']['full'],\n",
    "            generators['contrastive_train'],\n",
    "            epochs=epochs\n",
    "        )\n",
    "        \n",
    "        contrastive_time = time.time() - start_time\n",
    "        print(f\"⏱️  Contrastive Training completed in {contrastive_time:.1f}s\")\n",
    "        \n",
    "        # Train Triplet Model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📈 Training Triplet Model\")\n",
    "        print(\"=\"*50)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.histories['Triplet'] = train_triplet_model(\n",
    "            self.models['Triplet']['full'],\n",
    "            generators['triplet_train'],\n",
    "            epochs=epochs\n",
    "        )\n",
    "        \n",
    "        triplet_time = time.time() - start_time\n",
    "        print(f\"⏱️  Triplet Training completed in {triplet_time:.1f}s\")\n",
    "        \n",
    "        # Store training times\n",
    "        self.training_times = {\n",
    "            'BCE': bce_time,\n",
    "            'Contrastive': contrastive_time,\n",
    "            'Triplet': triplet_time\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n✅ All models trained successfully!\")\n",
    "        \n",
    "    def evaluate_all_models(self):\n",
    "        \"\"\"Evaluate all models on verification task\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📊 Evaluating All Models\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        test_pairs = self.data_pipeline['test_data']['pairs']\n",
    "        test_labels = self.data_pipeline['test_data']['labels']\n",
    "        \n",
    "        for model_name in ['BCE', 'Contrastive', 'Triplet']:\n",
    "            print(f\"\\n🔍 Evaluating {model_name} Model...\")\n",
    "            \n",
    "            fpr, tpr, roc_auc, eer = evaluate_model(\n",
    "                self.models[model_name]['base'],\n",
    "                test_pairs,\n",
    "                test_labels,\n",
    "                model_name\n",
    "            )\n",
    "            \n",
    "            self.results[model_name] = {\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'roc_auc': roc_auc,\n",
    "                'eer': eer,\n",
    "                'training_time': self.training_times[model_name]\n",
    "            }\n",
    "        \n",
    "        print(\"\\n✅ All models evaluated!\")\n",
    "        \n",
    "    def create_comprehensive_report(self):\n",
    "        \"\"\"Create comprehensive comparison report with visualizations\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"📈 Creating Comprehensive Comparison Report\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        \n",
    "        # 1. Training Loss Comparison\n",
    "        plt.subplot(2, 3, 1)\n",
    "        for model_name, history in self.histories.items():\n",
    "            epochs = range(1, len(history.history['loss']) + 1)\n",
    "            plt.plot(epochs, history.history['loss'], label=f'{model_name} Train Loss')\n",
    "            if 'val_loss' in history.history:\n",
    "                plt.plot(epochs, history.history['val_loss'], label=f'{model_name} Val Loss', linestyle='--')       \n",
    "        plt.title('Training Loss Comparison')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # 2. Training Accuracy (BCE Model)\n",
    "        plt.subplot(2, 3, 2)\n",
    "        if 'accuracy' in self.histories['BCE'].history: \n",
    "            epochs = range(1, len(self.histories['BCE'].history['accuracy']) + 1)\n",
    "            plt.plot(epochs, self.histories['BCE'].history['accuracy'], label='BCE Train Accuracy')\n",
    "            if 'val_accuracy' in self.histories['BCE'].history:\n",
    "                plt.plot(epochs, self.histories['BCE'].history['val_accuracy'], label='BCE Val Accuracy', linestyle='--')\n",
    "        plt.title('Training Accuracy (BCE Model)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()      \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
